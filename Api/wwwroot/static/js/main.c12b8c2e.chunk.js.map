{"version":3,"sources":["components/Speech/speech.js","App.js","reportWebVitals.js","index.js"],"names":["Speech","useSpeechRecognition","transcript","finalTranscript","interimTranscript","resetTranscript","browserSupportsSpeechRecognition","listening","useState","isListening","setIsListening","microphoneRef","useRef","word","words","setWords","className","stopHandle","current","classList","remove","SpeechRecognition","stopListening","ref","onClick","add","startListening","continuous","src","wordsSpokenArray","split","console","log","lastWord","length","fetch","then","res","json","data","catch","getLastWord","map","App","state","Component","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"wRAoGeA,EAjGA,WACb,IADmB,EASfC,iCANFC,EAHiB,EAGjBA,WAEAC,GALiB,EAIjBC,kBAJiB,EAKjBD,iBACAE,EANiB,EAMjBA,gBAEAC,GARiB,EAOjBC,UAPiB,EAQjBD,kCARiB,EAUmBE,oBAAS,GAV5B,mBAUZC,EAVY,KAUCC,EAVD,KAWbC,EAAgBC,iBAAO,MAXV,EAYOJ,mBAAS,CAAC,CAACK,KAAM,MAZxB,mBAYZC,EAZY,KAYLC,EAZK,KAanB,IAAKT,EACH,OACE,qBAAKU,UAAU,uBAAf,wDAKJ,IAQMC,EAAa,WACjBP,GAAe,GACfC,EAAcO,QAAQC,UAAUC,OAAO,aACvCC,IAAkBC,iBA6BpB,OACE,sBAAKN,UAAU,qBAAf,UACE,sBAAKA,UAAU,uBAAf,UACE,qBAAKA,UAAU,4BACfO,IAAKZ,EACLa,QA7CgB,WACpBd,GAAe,GACfC,EAAcO,QAAQC,UAAUM,IAAI,aACpCJ,IAAkBK,eAAe,CAC/BC,YAAY,KAuCV,SAGE,qBAAKC,IAjEQ,gDAiEaZ,UAAU,sBAEtC,qBAAKA,UAAU,oBAAf,SACGP,EAAc,qBAAuB,2BAEvCA,GACC,wBAAQO,UAAU,sBAAsBQ,QAASP,EAAjD,qBAMF,qBAAKD,UAAU,8BAAf,SACCP,GACD,sBAAKO,UAAU,8BAAf,UACE,qBAAKA,UAAU,yBAAf,SAAyCd,IACzC,mCAjCY,WAClB,GAAGC,EAAiB,CAClB,IAAI0B,EAAmB1B,EAAgB2B,MAAM,KAC7CC,QAAQC,IAAI7B,GACZ4B,QAAQC,IAAIH,GACZ,IAAMI,EAAWJ,EAAiBA,EAAiBK,OAAS,GAC5DH,QAAQC,IAAIC,GACZ5B,KAlBgBQ,EAmBLoB,IAjBTE,MAAM,eAAetB,GACpBuB,MAAK,SAAAC,GAAG,OAAIA,EAAIC,UAChBF,MAAK,SAACG,GACLxB,EAASwB,GACTR,QAAQC,IAAIO,MAEbC,MAAMT,QAAQC,KARF,IAACnB,EA4CT4B,KACH,qBAAKzB,UAAU,mBAAf,SACGF,EAAM4B,KAAI,SAAC7B,GAAD,OACP,uBAAsBG,UAAU,QAAhC,UAAyCH,EAAKA,KAA9C,OAAWA,EAAKA,WAGtB,wBAAQG,UAAU,uBAAuBQ,QAvD7B,WAClBP,IACAZ,KAqDM,4BCvESsC,G,kNAdbC,MAAQ,CACN9B,MAAQ,I,4CAIV,WACE,OACE,8BACE,cAAC,EAAD,U,GATU+B,cCOPC,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,6BAAqBZ,MAAK,YAAkD,IAA/Ca,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1BZ,M","file":"static/js/main.c12b8c2e.chunk.js","sourcesContent":["import './speech.css';\r\nimport { useRef, useState } from \"react\";\r\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\r\nconst Speech = () => {\r\n  let microPhoneIcon = \"https://img.icons8.com/ios/452/microphone.png\";\r\n  const {\r\n    transcript,\r\n    interimTranscript,\r\n    finalTranscript,\r\n    resetTranscript,\r\n    listening,\r\n    browserSupportsSpeechRecognition,\r\n  } = useSpeechRecognition();\r\n  const [isListening, setIsListening] = useState(false);\r\n  const microphoneRef = useRef(null);\r\n  const [words, setWords] = useState([{word: \"\"}]);\r\n  if (!browserSupportsSpeechRecognition) {\r\n    return (\r\n      <div className=\"mircophone-container\">\r\n        Browser is not Support Speech Recognition.\r\n      </div>\r\n    );\r\n  }\r\n  const handleListing = () => {\r\n    setIsListening(true);\r\n    microphoneRef.current.classList.add(\"listening\");\r\n    SpeechRecognition.startListening({\r\n      continuous: true,\r\n    });\r\n    \r\n  };\r\n  const stopHandle = () => {\r\n    setIsListening(false);\r\n    microphoneRef.current.classList.remove(\"listening\");\r\n    SpeechRecognition.stopListening();\r\n    };\r\n  const handleReset = () => {\r\n    stopHandle();\r\n    resetTranscript();\r\n    };\r\n  \r\n  const fetchWords = (word) => {\r\n      if(word){\r\n        fetch(\"/api/rhymes/\"+word)\r\n        .then(res => res.json())\r\n        .then((data) => {\r\n          setWords(data)\r\n          console.log(data)\r\n        })\r\n        .catch(console.log)\r\n      }\r\n    }\r\n  const getLastWord = () => {\r\n    if(finalTranscript) {\r\n      let wordsSpokenArray = finalTranscript.split(' ');\r\n      console.log(finalTranscript);\r\n      console.log(wordsSpokenArray);\r\n      const lastWord = wordsSpokenArray[wordsSpokenArray.length - 1];\r\n      console.log(lastWord);\r\n      resetTranscript();\r\n      fetchWords(lastWord)\r\n    }\r\n  }\r\n  return (\r\n    <div className=\"microphone-wrapper\">\r\n      <div className=\"mircophone-container\">\r\n        <div className=\"microphone-icon-container\"\r\n        ref={microphoneRef}\r\n        onClick={handleListing}>\r\n          <img src={microPhoneIcon} className=\"microphone-icon\" />\r\n        </div>\r\n        <div className=\"microphone-status\">\r\n          {isListening ? \"Listening.........\" : \"Click to start Rapping\"}\r\n        </div>\r\n        {isListening && (\r\n          <button className=\"microphone-stop btn\" onClick={stopHandle}>\r\n            Stop\r\n          </button>\r\n        )}\r\n      </div>\r\n\r\n        <div className=\"microphone-result-container\">\r\n        {isListening && (\r\n        <div className=\"microphone-result-container\">\r\n          <div className=\"microphone-result-text\">{transcript}</div>\r\n          <>{getLastWord()}</>\r\n          <div className=\"rhymes-container\">\r\n            {words.map((word) => (\r\n                <span key={word.word} className=\"rhyme\">{word.word}, </span>\r\n            ))}\r\n          </div>\r\n          <button className=\"microphone-reset btn\" onClick={handleReset}>\r\n            Reset\r\n          </button>\r\n        </div>\r\n      )}\r\n        </div>\r\n    </div>\r\n  );\r\n}\r\nexport default Speech;","\n    import React, { Component } from 'react';\n    import Speech from './components/Speech/speech';\n    import './App.css';\n\n    class App extends Component {\n      state = {\n        words : []\n      }\n\n      \n      render() {\n        return (\n          <div>\n            <Speech></Speech>\n          </div>\n        );\n      }\n    }\n\n    export default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}